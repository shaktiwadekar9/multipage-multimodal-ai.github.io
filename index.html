<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
        button {
            background: #5E5DF0;
            border-radius: 999px;
            box-shadow: #5E5DF0 0 10px 20px -10px;
            box-sizing: border-box;
            color: #FFFFFF;
            cursor: pointer;
            font-family: Inter,Helvetica,"Apple Color Emoji","Segoe UI Emoji",NotoColorEmoji,"Noto Color Emoji","Segoe UI Symbol","Android Emoji",EmojiSymbols,-apple-system,system-ui,"Segoe UI",Roboto,"Helvetica Neue","Noto Sans",sans-serif;
            font-size: 16px;
            font-weight: 700;
            line-height: 24px;
            opacity: 1;
            outline: 0 solid transparent;
            padding: 8px 18px;
            user-select: none;
            -webkit-user-select: none;
            touch-action: manipulation;
            width: fit-content;
            word-break: break-word;
            border: 0;
        }
    </style>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="button.css">
</head>
<body>
    <!-- h1 for the first header, h2 for its subheading, h3 for subsub heading-->
    <h1 style="font-size: 35px">Multipage Multimodal Transformer model and RAG sytem for PDF understanding</h1>
    <a href="https://github.com/shaktiwadekar9">
        <!-- HTML !-->
        <button>Shakti Wadekar</button>
    </a>
    <!-- p for paragraph -->
    <p style="font-size: 24px">This project builds a RAG (Retrieval-Augmented-Generation) system using Multipage Multimodal Transformer to chat with your PDFs</p>

    <img class="img-mmrag-txtrag" src="imgs/contrast_llm_multimodal.png" alt="Multimodal RAG sytem">

    <div class="center-text">
        <h3>Major changes required in current RAG systems</h2>
        <ul>
            <li>Ingestion: Need to embed pages, instead of embedding text and images in page separately. Because page has text, table and images in a layout which are coorelated with each other.</li>
            <li>Retrieval: Need a Multimodal model which can correlate the user query to page embeddings.</li>
            <li>Generation: Need a Multimodal model which has ability to input multiple pages at a time. Since pdf context is present on multiple pages, a model being able to process multiple pages can generate comprehensive answers.</li>
        </ul>
        1. Ingestion: Need to embed pages, instead of embedding text and images in page separately. Because page has text, table and images in a layout which are coorelated with each other.
        <br>
        2. Retrieval: Need a Multimodal model which can correlate the user query to page embeddings
        <br>
        3. Generation: Need a Multimodal model which has ability to input multiple pages at a time. Since pdf context is present on multiple pages, a model being able to process multiple pages can generate comprehensive answers.
    </div>
    <div class="center-text">
        <p>How build such a system?</p>
        
        1. Train multimodal model for Q&A on single pdf page with text, table, chart, plot and figures.
        <br>
        2. Extend this multimodal architecture to handle multiple pages.
        <br>
        3. Train this new multipage multimodal model for Q&A on multipage pdfs.
        <br>
        4. The model will always will have page limits, hence need to build a retriever which can fetch best top-k pages for Q&A.
        <br>
        5. Some test text
        
    </div>
    
    

    

    <!-- hr for horizontal line -->

    <!--img class="img-mmrag-txtrag" src="imgs/llm_chat_mm_chat_transition.png" alt="Multimodal RAG sytem"-->
    <!--img class="img-mmrag" src="imgs/mmrag.png" alt="mmrag" title="Multimodal RAG"-->
    
    <!--img class="img-txtrag" src="imgs/txtrag.png" alt="textrag" title="Text based RAG"-->

    
    
</body>
</html>